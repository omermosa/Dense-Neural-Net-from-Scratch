{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.read_csv(\"training_features.txt\")\n",
    "y_train=pd.read_csv(\"training_labels.txt\")\n",
    "X_test=pd.read_csv(\"test_features.txt\").values\n",
    "y_test=pd.read_csv(\"test_labels.txt\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['y_train']=y_train\n",
    "\n",
    "X_train=X_train.sample(frac=1)\n",
    "X_train\n",
    "y_train=X_train['y_train'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=X_train['y_train'].values\n",
    "y_train=y_train.reshape(-1,1)\n",
    "X_train=X_train.drop(['y_train'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 10\n",
    "train_size = y_train.shape[0]\n",
    "y_train = y_train.reshape(1, train_size)\n",
    "y_train = np.eye(classes)[y_train.astype('int32')-1]\n",
    "y_train = y_train.T.reshape(classes, train_size)\n",
    "\n",
    "test_size = y_test.shape[0]\n",
    "y_test = y_test.reshape(1, test_size)\n",
    "y_test = np.eye(classes)[y_test.astype('int32')-1]\n",
    "y_test= y_test.T.reshape(classes, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.T\n",
    "y_test=y_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[4].reshape(16,16), cmap='gray', vmin=0, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of hidden layers1\n"
     ]
    }
   ],
   "source": [
    "NH=int(input('Num of hidden layers'))\n",
    "yt=y_train.flatten()\n",
    "n_o=10 #num of output layer nodes= num of unique classes\n",
    "n_i=X_train.shape[1] #num of input layer nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of nodes in  layers num 1: 100\n"
     ]
    }
   ],
   "source": [
    "NN=[]\n",
    "NN.append(n_i)\n",
    "for i in range(NH):\n",
    "    n=int(input('Num of nodes in  layers num %d: '%(i+1)))\n",
    "    NN.append(n)\n",
    "NN.append(n_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(Z):\n",
    "    return 1/(1+np.exp(-1*Z))\n",
    "def Relu(Z):\n",
    "    return np.maximum(Z,0)\n",
    "def initialize_layers(NN,NH):\n",
    "    #we have NH hideen layers with NN[i] nodes each\n",
    "    #we want to initialize Weights for each layer where each Weight vector for a node is num of connected prev nodes\n",
    "    Wts={}\n",
    "    for layer in range (1,len(NN)):\n",
    "        Wts['W'+str(layer)]=np.random.randn(NN[layer],NN[layer-1])/100 #array of vectors for each node.\n",
    "        Wts['b'+str(layer)]=np.zeros((NN[layer],1)) #bias per layer, make it a vector to allow for vectorization.\n",
    "    return Wts\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wts=initialize_layers(NN,NH)\n",
    "Wts['b1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Forward_Prob(Xt,Wts,NN):\n",
    "    # we need to store W,b,inputs,outputs,activations for each layer for each node\n",
    "    parameters=[]\n",
    "    Ai=Xt #current layer output\n",
    "   \n",
    "    Ap=Ai #previous layer output (current layer input)\n",
    "    for i in range(1,len(NN)-1):\n",
    "        W,b=Wts['W'+str(i)],Wts['b'+str(i)]\n",
    "        Ap=Ai\n",
    "        Z=np.dot(W,Ap.T)+b\n",
    "        actv=Relu(Z)\n",
    "        Ai=actv.T\n",
    "       # print(Ai.shape,Ap.shape,actv.shape)\n",
    "        #print(Wts['b'+str(i)])\n",
    "        parameters.append((W,b,Ap,actv,Z))\n",
    "    W,b=Wts['W'+str(len(NN)-1)],Wts['b'+str(len(NN)-1)]\n",
    "    Ap=Ai\n",
    "    Z=np.dot(W,Ap.T)+b\n",
    "    actv=Sigmoid(Z) #np.exp(Z) / np.sum(np.exp(Z), axis=0)#\n",
    "    Ai=actv.T\n",
    "   # print(Ai.shape,Ap.shape,actv.shape)\n",
    "    #print(Wts['b'+str(i)])\n",
    "    parameters.append((W,b,Ap,actv,Z))\n",
    "    Ao=Ai #output of last layer=last Ai   \n",
    "    #print(len(parameters))\n",
    "    return parameters, Ao \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get predictions\n",
    "def get_yp(Ao):\n",
    "    y_p= np.array([(np.argmax(a)+1) for a in Ao]).reshape(-1,1)\n",
    "   # print(y_p.shape)\n",
    "    return y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function returns the avg error\n",
    "def Loss(y_true,prediction):\n",
    "    y_p=prediction\n",
    "    m=y_true.shape[0]\n",
    "    loss = -1/m*np.sum(np.multiply(y_true, np.log(y_p))+np.multiply(1-y_true, np.log(1-y_p)))\n",
    "    return loss\n",
    "                \n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probgate backwards\n",
    "def Back_Prob(y_true, Ao, parameters,Wts,NN):\n",
    "    #dAo = - (np.divide(Ao, y_true))  #last layer derivative\n",
    "    dZ =(Ao-y_true)\n",
    "    derivatives={}\n",
    "    \n",
    "    m=y_true.shape[0]\n",
    "    W,b,X,A,Z=parameters[len(NN)-2]\n",
    "    \n",
    "    dW=1.0/m*np.matmul(dZ.T,X)\n",
    "    #print(A==Sigmoid(np.dot(W,X.T)+b))\n",
    "    db = (1/(m)) * np.sum(dZ, axis =0, keepdims = True).T\n",
    "    derivatives['dW'+str(len(NN)-1)]=dW\n",
    "    derivatives['db'+str(len(NN)-1)]=db\n",
    "    dAp = np.matmul( dZ,W)\n",
    "   # print(W)\n",
    "    for i in reversed(range(len(NN)-2)):\n",
    "        Wp=W\n",
    "        Xp=X\n",
    "        dA=dAp\n",
    "        W,b,X,A,Z=parameters[i]\n",
    "        dZp=dZ\n",
    "        \n",
    "        dZ=np.maximum(Z,0).T*dAp#np.dot(dZp,Wp) * (1 - np.power(A.T, 2))# #vectorized implementation of oh in the slides\n",
    "        m=X.shape[0]\n",
    "        dW=1.0/m*np.matmul(dZ.T,X)\n",
    "        db = (1/(m)) * np.sum(dZ, axis =0, keepdims = True).T\n",
    "        \n",
    "        #print(dZp.shape,X.shape,Wp.shape,A.shape, db.shape,dZ.shape)\n",
    "        derivatives['dW'+str(i+1)]=dW\n",
    "        derivatives['db'+str(i+1)]=db\n",
    "        dAp=np.matmul(dZ,W)\n",
    "    return derivatives\n",
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update all Wts.\n",
    "def update(derivatives,Wts,parameters,learning_rate,NN):\n",
    "    for i in range(1,len(NN)):\n",
    "        #print(i)\n",
    "        Wts['b'+str(i)]=Wts['b'+str(i)]-learning_rate*derivatives['db'+str(i)]\n",
    "        Wts['W'+str(i)]=Wts['W'+str(i)]-learning_rate*derivatives['dW'+str(i)]\n",
    "    #print(Wts['W2'])\n",
    "    return Wts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "def Train_NN(iterations,X_train,y_train,NN,NH,learning_rate):\n",
    "    Wts=initialize_layers(NN,NH)\n",
    "    i=0\n",
    "    loss=1\n",
    "    losses=[]\n",
    "    while i< iterations:\n",
    "        parameters,Ao=Forward_Prob(X_train,Wts,NN)\n",
    "        #loss=Loss(y_train,Ao)\n",
    "        #print(Ao)\n",
    "        derivatives=Back_Prob(y_train,Ao,parameters,Wts,NN)\n",
    "        Wts=update(derivatives,Wts,parameters,learning_rate,NN)\n",
    "        losses.append(loss)\n",
    "        i+=1\n",
    "        #print(i)\n",
    "    return (Wts,losses)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict the outcomes\n",
    "def Predict(Wts,X_test):\n",
    "    parameters,predict=Forward_Prob(X_test,Wts,NN)\n",
    "    predict=np.array(predict)\n",
    "    print(predict.shape)\n",
    "    predictions=get_yp(predict)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4999, 10)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.91      0.97      0.94       499\n",
      "           2       0.90      0.85      0.87       500\n",
      "           3       0.80      0.78      0.79       500\n",
      "           4       0.91      0.95      0.93       500\n",
      "           5       0.82      0.74      0.78       500\n",
      "           6       0.92      0.89      0.90       500\n",
      "           7       0.93      0.92      0.92       500\n",
      "           8       0.81      0.80      0.81       500\n",
      "           9       0.86      0.90      0.88       500\n",
      "          10       0.88      0.95      0.91       500\n",
      "\n",
      "    accuracy                           0.87      4999\n",
      "   macro avg       0.87      0.87      0.87      4999\n",
      "weighted avg       0.87      0.87      0.87      4999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "it=1000\n",
    "eta=.2\n",
    "Wts,losses=Train_NN(it,X_train,y_train,NN,NH,eta)\n",
    "y_p=Predict(Wts,X_test)\n",
    "yt=get_yp(y_test)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(yt,y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[0.01111831, 0.02856519, 0.02968252, ..., 0.01323527, 0.0292424 ,\n",
       "         0.01213451],\n",
       "        [0.00987607, 0.03036944, 0.03388191, ..., 0.02140788, 0.03373982,\n",
       "         0.01186591],\n",
       "        [0.01535444, 0.02806048, 0.03214885, ..., 0.01406045, 0.0278088 ,\n",
       "         0.01466955],\n",
       "        ...,\n",
       "        [0.00857407, 0.03021102, 0.03209848, ..., 0.01991606, 0.03331432,\n",
       "         0.01164121],\n",
       "        [0.00842829, 0.03177087, 0.03431749, ..., 0.01924894, 0.02487756,\n",
       "         0.00952012],\n",
       "        [0.00978166, 0.02939611, 0.03277802, ..., 0.02004853, 0.02702139,\n",
       "         0.01648262]]), 'b1': array([[1.18994225],\n",
       "        [1.19070658],\n",
       "        [1.19139309],\n",
       "        [1.1922555 ],\n",
       "        [1.19150984],\n",
       "        [1.1914254 ],\n",
       "        [1.19109315],\n",
       "        [1.19192528],\n",
       "        [1.19128727],\n",
       "        [1.19060811],\n",
       "        [1.19138658],\n",
       "        [1.192078  ],\n",
       "        [1.19091784],\n",
       "        [1.19133918],\n",
       "        [1.1908083 ],\n",
       "        [1.19174915],\n",
       "        [1.19090079],\n",
       "        [1.19149829],\n",
       "        [1.19122738],\n",
       "        [1.19153316]]), 'W2': array([[35.3959107 , 35.39837684, 35.39547767, 35.39399449, 35.3963723 ,\n",
       "         35.39053913, 35.39629215, 35.40580929, 35.38930223, 35.39767839,\n",
       "         35.40320823, 35.39029544, 35.39712256, 35.38976737, 35.38100007,\n",
       "         35.39022605, 35.39514873, 35.39024516, 35.38936658, 35.40916575],\n",
       "        [35.38681251, 35.38824415, 35.38763221, 35.38454817, 35.38865421,\n",
       "         35.3863604 , 35.38562617, 35.39289897, 35.3859008 , 35.38140932,\n",
       "         35.38861997, 35.38324113, 35.3956276 , 35.37904355, 35.37354053,\n",
       "         35.38515029, 35.38389555, 35.3784193 , 35.38000242, 35.39795079],\n",
       "        [35.38719882, 35.39450151, 35.38544491, 35.38602813, 35.3874533 ,\n",
       "         35.38099673, 35.38644449, 35.39756927, 35.3881813 , 35.38789363,\n",
       "         35.39687568, 35.37810008, 35.39335823, 35.37813896, 35.3750196 ,\n",
       "         35.38596933, 35.39179971, 35.38264503, 35.38621706, 35.39547427],\n",
       "        [35.396302  , 35.39460776, 35.39593612, 35.39288623, 35.39207971,\n",
       "         35.39720084, 35.40138196, 35.40873221, 35.38756472, 35.39268949,\n",
       "         35.40086435, 35.39496869, 35.40350549, 35.3916876 , 35.38190971,\n",
       "         35.38788183, 35.40042978, 35.3903187 , 35.38865768, 35.40471318],\n",
       "        [35.39209923, 35.39120077, 35.38748532, 35.38732065, 35.39517547,\n",
       "         35.38532874, 35.39198324, 35.40002068, 35.38574223, 35.39407207,\n",
       "         35.39387823, 35.38996965, 35.39240717, 35.38677097, 35.38224767,\n",
       "         35.38716811, 35.39434276, 35.39046482, 35.39012952, 35.40139738],\n",
       "        [35.37965616, 35.38909274, 35.38431322, 35.378748  , 35.38259695,\n",
       "         35.37665758, 35.38455461, 35.39587103, 35.38024779, 35.37861565,\n",
       "         35.38926031, 35.37770701, 35.38340124, 35.37290472, 35.3708169 ,\n",
       "         35.37345644, 35.38515754, 35.37581481, 35.38153406, 35.39361847],\n",
       "        [35.40141507, 35.3996648 , 35.40461477, 35.39730229, 35.39814271,\n",
       "         35.40072274, 35.40059611, 35.40680904, 35.39542852, 35.39707423,\n",
       "         35.40757813, 35.39830384, 35.40446748, 35.3896949 , 35.39130099,\n",
       "         35.39710856, 35.40223123, 35.38946964, 35.39377473, 35.40361213],\n",
       "        [35.3812038 , 35.38479494, 35.38765614, 35.38488571, 35.38757043,\n",
       "         35.37750556, 35.38821049, 35.39481816, 35.38077211, 35.3801237 ,\n",
       "         35.38824598, 35.38237037, 35.39120076, 35.37337186, 35.37060845,\n",
       "         35.37546734, 35.38391327, 35.37545357, 35.38363775, 35.39531677],\n",
       "        [35.39017   , 35.3937574 , 35.3821364 , 35.37904504, 35.38362091,\n",
       "         35.38769304, 35.38623867, 35.39924753, 35.38125162, 35.38935232,\n",
       "         35.39281471, 35.3839995 , 35.39085004, 35.3855268 , 35.37414088,\n",
       "         35.38372198, 35.38609779, 35.37836157, 35.38881935, 35.39565404],\n",
       "        [35.37490904, 35.38590182, 35.38285438, 35.37318284, 35.3782909 ,\n",
       "         35.37942126, 35.37994028, 35.38978529, 35.37868882, 35.37752513,\n",
       "         35.38754214, 35.37963027, 35.38361625, 35.37141073, 35.37072296,\n",
       "         35.37132301, 35.38600878, 35.36924275, 35.37970655, 35.38132928]]), 'b2': array([[35.65374039],\n",
       "        [35.64693488],\n",
       "        [35.64878204],\n",
       "        [35.65023623],\n",
       "        [35.64884076],\n",
       "        [35.64452705],\n",
       "        [35.65114418],\n",
       "        [35.64666067],\n",
       "        [35.64744702],\n",
       "        [35.64556726]])}"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
